{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the corpus we will be using, which is included in NLTK. You will need NLTK and Scikit-learn (as well as their dependencies, in particular scipy and numpy) to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"reuters\") # if necessary\n",
    "from nltk.corpus import reuters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK sample of the Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and is divided into a training and test sets, a split which we will preserve here. Let's look at the counts of texts of the various categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for category in reuters.categories():\n",
    "    print category, len(reuters.fileids(category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the documents in the corpus are tagged with multiple labels; in this situation, a straightforward approach is to build a classifier for each label. Let's build a classifier to distinguish the most common topic in the corpus, \"acq\" (acqusitions). First, here's some code to build a dataset in preparation for classification using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def get_BOW(text):\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "\n",
    "def prepare_reuters_data(topic,feature_extractor):\n",
    "    feature_matrix = []\n",
    "    classifications = []\n",
    "    for file_id in reuters.fileids():\n",
    "        feature_dict = feature_extractor(reuters.words(file_id))   \n",
    "        feature_matrix.append(feature_dict)\n",
    "        if topic in reuters.categories(file_id):\n",
    "            classifications.append(topic)\n",
    "        else:\n",
    "            classifications.append(\"not \" + topic)\n",
    "     \n",
    "    vectorizer = DictVectorizer()\n",
    "    dataset = vectorizer.fit_transform(feature_matrix)\n",
    "    return dataset,classifications\n",
    "\n",
    "dataset,classifications = prepare_reuters_data(\"acq\",get_BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code builds a sparse bag of words feature representation (a Python dictionary) for each text in the corpus (which is pre-tokenized) and puts it in a list; a corresponding list of correct classifications is created at the same time. The scikit-learn DictVectorizer class converts Python dictionaries into the scipy sparse matrices which Scikit-learn uses; when working with a single datset, use the fit_transform method to perform the conversion. Next, let's prepare a Random Forest classifier to test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we are using default settings for this classifier. Let's do 10-fold crossvalidation, and looking at the accuracy, recall, precision, and f1-score... (if you are using the latest version of scikit learn (0.18) you will get a depreciation warning when using cross_validation, since cross_validation is now included under feature_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def check_results(predictions, classifications):\n",
    "    print \"accuracy\"\n",
    "    print accuracy_score(classifications,predictions)\n",
    "    print classification_report(classifications,predictions)\n",
    "\n",
    "predictions = cross_validation.cross_val_predict(clf, dataset,classifications, cv=10)\n",
    "check_results(predictions, classifications)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the classifier is not obviously biased towards a particular task, so accuracy and f-score are nearly the same. The performance is quite high, indicating that it is a fairly easy classification task. Let's try to improve performance by removing stopwords and doing lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def get_BOW_lowered_no_stopwords(text):\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords:\n",
    "            BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "\n",
    "dataset, classification = prepare_reuters_data(\"acq\",get_BOW_lowered_no_stopwords)\n",
    "predictions = cross_validation.cross_val_predict(clf, dataset,classifications, cv=10)\n",
    "check_results(predictions, classifications)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gain in performance was fairly modest.\n",
    "\n",
    "The default number of decision trees (n_estimators) used in the model is only 10, which is fairly low: lets see if we can find a better number..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_to_test = [5,50,100,150,300]\n",
    "clfs = [RandomForestClassifier(n_estimators=n) for n in n_to_test]\n",
    "for clf in clfs:\n",
    "    predictions = cross_validation.cross_val_predict(clf, dataset,classifications, cv=10)\n",
    "    check_results(predictions, classifications)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, more subclassifiers improved things, though at the cost of speed. Feel free to play around more with this or another classifier to see if you can do better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
